\secput{simple}{Known Solutions}
We examine several simple solutions to the iterated predecessor problem. 
These solutions provide a good background for understanding range coalescing and
serve as our implementation baselines in \secref{results}.

\subsection*{Sequential Binary Search}
The simplest solution to the iterative predecessor query problem 
is to do a binary search on each of the $k$ unmodified lists 
$L_1 \ldots L_k$, and write 
down the output from each. Since each binary search requires $O(\lg \paren{n/B})$ memory transfers, 
this solution requires a total of $O(k \lg \paren{n/B})$ memory transfers. The total space 
usage is optimal, $O(kn)$.

\subsection*{Sequential vEB Binary Search}
Using the vEB layout described previously, we can do binary searches using only 
$O(\log_{B+1} n)$. If we use a vEB layout for each of the $k$ lists, we can perform 
the searches in $O(k \log_{B+1} n)$. The total space usage is optimal, $O(kn)$.

\subsection*{Fractional Cascading}
Fractional cascading~\cite{ChazelleGu86} is the incumbent solution for the in-memory iterated 
predecessor query problem. An external memory oriented extension of fractional cascading
described below achieves a runtime of $O(\log_{B+1} n + k)$.

The main idea behind fractional cascading is to use the query result from 
each list to perform a search on the next list in 
constant time.  One needs only to do a binary search on the first list to prime the
pipeline.  To do this, we store pointers in each list to its predecessor and 
successor in the next list. This gives us a constant-sized range to 
search through in the next list.

If we did this naively, this would be of no benefit --- the predecessor and 
successor of the $i$th list could span the entirety of the $i+1$st list. 
However, by altering the lists slightly, 
we can achieve constant time per remaining search. Starting with the last list, 
we insert every other element into the previous list. We do this for each list. 
This ensures that the range between predecessor and successor is at most a constant value.

We store the initial list in the vEB layout to minimize memory transfers for the 
initial binary searches. Using this method, we can perform a query using 
$O(\log_{B+1} n + k)$ memory transfers. The total space usage is optimal, $O(kn)$.

\subsection*{Quadratic Storage}
A brute-force fast solution involves storing one sorted $kn$-length list 
of all elements from all lists using the vEB layout. Accompanying each element in the list is 
a $k$-length sublist with a copy of its $k$ predecessors, 
one from each list in $\{ L_1 \ldots L_k \}$. 
We can iterate over this contiguous sublist using $O(k/B)$ memory transfers, 
so the total number of memory transfers is $O(\log_{B+1} \paren{kn} + k/B)$. However, the
total space usage is $O(nk^2)$, since we must store a $k$-length sublist for each element.



